{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b00GdKCA9JN7"
      },
      "source": [
        "# Deep Learning with PyTorch : Build a Generative Adversarial Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4GVaDSlOSf"
      },
      "source": [
        "import torch\n",
        "torch.manual_seed(42)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sDyr-Qp4FPe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwklBE_vlOSi"
      },
      "source": [
        "# Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oUWVmkulOSi"
      },
      "source": [
        "device=\"cuda\" # image=image.to(device)\n",
        "batch_size=128 # trainloader, training loop\n",
        "noise_dim=64   # creating generator model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer parameters(Adam)\n",
        "lr=0.0002\n",
        "beta_1=0.5\n",
        "beta_2=0.99"
      ],
      "metadata": {
        "id": "dIR7tU-wYvPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training variable\n",
        "epochs=20"
      ],
      "metadata": {
        "id": "iRTiDWHHY79z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thRDmRxBlOSj"
      },
      "source": [
        "# Load MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms as T"
      ],
      "metadata": {
        "id": "UV-DOd1ZY7Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_augs= T.Compose([\n",
        "    T.RandomRotation((-20, +20)),\n",
        "    T.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "VqBqVpr0YuPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA70KkPWlOSj"
      },
      "source": [
        "trainset=datasets.MNIST(\"MNIST/\", download=True, train=True, transform= train_augs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RPRGJDAlOSk"
      },
      "source": [
        "image, label=trainset[19]\n",
        "plt.imshow(image.squeeze(), cmap=\"gray\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORt5m1TvlOSk"
      },
      "source": [
        "print(\"number of images in this dataset is:\", len(trainset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRSk3zV1lOSl"
      },
      "source": [
        "# Load Dataset Into Batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaRQzZhr7-HF"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDNysctVlOSl"
      },
      "source": [
        "trainloader=DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "print(\"total number of batches is :\", len(trainloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me1C0THUlOSm"
      },
      "source": [
        "# load one batch in trainloader\n",
        "images, _ =next(iter(trainloader))\n",
        "print(images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R3XRbXBlOSm"
      },
      "source": [
        "# 'show_tensor_images' : function is used to plot some of images from the batch\n",
        "\n",
        "def show_tensor_images(tensor_img, num_images = 16, size=(1, 28, 28)):\n",
        "    unflat_img = tensor_img.detach().cpu()\n",
        "    img_grid = make_grid(unflat_img[:num_images], nrow=4)\n",
        "    plt.imshow(img_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVLG2TA4lOSm"
      },
      "source": [
        "show_tensor_images(images, num_images=65)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb1rVzijlOSn"
      },
      "source": [
        "# Create Discriminator Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22qSpIBlknec"
      },
      "source": [
        "#In case if torch summary is not installed\n",
        "\n",
        "!pip install torchsummary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYvzxU2llOSn"
      },
      "source": [
        "from torch import nn\n",
        "from torchsummary import summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtQoJvmrAxTj"
      },
      "source": [
        "'''\n",
        "\n",
        "Network : Discriminator\n",
        "\n",
        "input : (bs, 1, 28, 28)\n",
        "      |                                                                                               ---- SUMMARY ----\n",
        "      V\n",
        "Conv2d( in_channels = 1, out_channels = 16, kernel_size = (3,3), stride = 2)                           #(bs, 16, 13, 13)\n",
        "BatchNorm2d()                                                                                          #(bs, 16, 13, 13)\n",
        "LeakyReLU()                                                                                            #(bs, 16, 13, 13)\n",
        "      |\n",
        "      V\n",
        "Conv2d( in_channels = 16, out_channels = 32, kernel_size = (5,5), stride = 2)                          #(bs, 32, 5, 5)\n",
        "BatchNorm2d()                                                                                          #(bs, 32, 5, 5)\n",
        "LeakyReLU()                                                                                            #(bs, 32, 5, 5)\n",
        "      |\n",
        "      V\n",
        "Conv2d( in_channels = 32, out_channels = 64, kernel_size = (5,5), stride = 2)                          #(bs, 64, 1, 1)\n",
        "BatchNorm2d()                                                                                          #(bs, 64, 1, 1)\n",
        "LeakyReLU()                                                                                            #(bs, 64, 1, 1)\n",
        "      |\n",
        "      V\n",
        "Flatten()                                                                                              #(bs, 64)\n",
        "Linear(in_features = 64, out_features = 1)                                                             #(bs, 1)\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VpIDdx9lOSn"
      },
      "source": [
        "def get_disc_block(in_channels, out_channels, kernel_size, stride):\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, kernel_size, stride),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.LeakyReLU(0.2)\n",
        "      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq_aX7EslOSo"
      },
      "source": [
        "from torch.nn.modules.flatten import Flatten\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.block_1=get_disc_block(1, 16, (3, 3), 2)\n",
        "    self.block_2=get_disc_block(16, 32, (5, 5), 2)\n",
        "    self.block_3=get_disc_block(32, 64, (5, 5), 2)\n",
        "\n",
        "    self.flatten= nn.Flatten()\n",
        "    self.linear=nn.Linear(in_features= 64, out_features=1)\n",
        "\n",
        "  def forward(self, images):\n",
        "    x1=self.block_1(images)\n",
        "    x2=self.block_2(x1)\n",
        "    x3=self.block_3(x2)\n",
        "    x4=self.flatten(x3)\n",
        "    x5=self.linear(x4)\n",
        "    return x5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqZFM47slOSo"
      },
      "source": [
        "D=Discriminator()\n",
        "D.to(device)\n",
        "\n",
        "summary(D, input_size=(1, 28,28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaSM5ky-lOSp"
      },
      "source": [
        "# Create Generator Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeBHYF5IAzFm"
      },
      "source": [
        "'''\n",
        "\n",
        "Network : Generator\n",
        "\n",
        "z_dim = 64\n",
        "input : (bs,z_dim)\n",
        "\n",
        "      |\n",
        "      | Reshape\n",
        "      V\n",
        "\n",
        "input : (bs, channel, height, width) -> (bs, z_dim , 1 , 1)\n",
        "      |                                                                                               ---- SUMMARY ----\n",
        "      V\n",
        "ConvTranspose2d( in_channels = z_dim, out_channels = 256, kernel_size = (3,3), stride = 2)             #(bs, 256, 3, 3)\n",
        "BatchNorm2d()                                                                                          #(bs, 256, 3, 3)\n",
        "ReLU()                                                                                                 #(bs, 256, 3, 3)\n",
        "      |\n",
        "      V\n",
        "ConvTranspose2d( in_channels = 256, out_channels = 128, kernel_size = (4,4), stride = 1)               #(bs, 128, 6, 6)\n",
        "BatchNorm2d()                                                                                          #(bs, 128, 6, 6)\n",
        "ReLU()                                                                                                 #(bs, 128, 6, 6)\n",
        "      |\n",
        "      V\n",
        "ConvTranspose2d( in_channels = 128, out_channels = 64, kernel_size = (3,3), stride = 2)                #(bs, 64, 13, 13)\n",
        "BatchNorm2d()                                                                                          #(bs, 64, 13, 13)\n",
        "ReLU()                                                                                                 #(bs, 64, 13, 13)\n",
        "      |\n",
        "      V\n",
        "ConvTranspose2d( in_channels = 64, out_channels = 1, kernel_size = (4,4), stride = 2)                  #(bs, 1, 28, 28)\n",
        "Tanh()                                                                                                 #(bs, 1, 28, 28)\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmGinLUjlOSp"
      },
      "source": [
        "def get_gen_block(in_channels, out_channels, kernel_size, stride, final_block=False):\n",
        "  if final_block==True:\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "  return nn.Sequential(\n",
        "      nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.ReLU()\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNcWK2malOSq"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, noise_dim):\n",
        "    super(Generator, self).__init__()\n",
        "    self.noise_dim=noise_dim\n",
        "    self.block_1=get_gen_block(noise_dim, 256, (3,3), 2)\n",
        "    self.block_2=get_gen_block(256, 128, (4,4), 1)\n",
        "    self.block_3=get_gen_block(128,64, (3,3), 2)\n",
        "    self.block_4=get_gen_block(64, 1, (4,4), 2, final_block=True)\n",
        "\n",
        "  def forward(self, r_noise_vec):\n",
        "    # (bs, noise_dim) -> (bs, noise_deim, 1, 1)\n",
        "    x=r_noise_vec.view(-1, self.noise_dim, 1, 1)\n",
        "    x1= self.block_1(x)\n",
        "    x2= self.block_2(x1)\n",
        "    x3=self.block_3(x2)\n",
        "    x4=self.block_4(x3)\n",
        "    return x4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyOp5x61lOSr",
        "scrolled": true
      },
      "source": [
        "G=Generator(noise_dim)\n",
        "G.to(device)\n",
        "\n",
        "summary(G, input_size=(1, noise_dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6v-NfQlVy8v"
      },
      "source": [
        "# Replace Random initialized weights to Normal weights\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpMoglmaUPnt"
      },
      "source": [
        "D=D.apply(weights_init)\n",
        "G=G.apply(weights_init)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLGG2YkRlOSr"
      },
      "source": [
        "# Create Loss Function and Load Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOvcqBuylOSs"
      },
      "source": [
        "def real_loss(disc_pred):\n",
        "  criterion=nn.BCEWithLogitsLoss()\n",
        "  ground_truth=torch.ones_like(disc_pred)\n",
        "  loss=criterion(disc_pred, ground_truth)\n",
        "  return loss\n",
        "\n",
        "def fake_loss(disc_pred):\n",
        "  criterion=nn.BCEWithLogitsLoss()\n",
        "  ground_truth=torch.zeros_like(disc_pred)\n",
        "  loss=criterion(disc_pred, ground_truth)\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96EEpkp9lOSs"
      },
      "source": [
        "D_opt= torch.optim.Adam(D.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
        "G_opt= torch.optim.Adam(G.parameters(), lr=lr, betas=(beta_1, beta_2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF_k10LElOSt"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmPLh41ulOSt"
      },
      "source": [
        "for i in range(epochs):\n",
        "  total_d_loss=0.0\n",
        "  total_g_loss=0.0\n",
        "  for real_img, _ in tqdm(trainloader):\n",
        "    real_img=real_img.to(device)\n",
        "    noise=torch.randn(batch_size, noise_dim, device=device)\n",
        "    # find the loss and update weights\n",
        "    D_opt.zero_grad()\n",
        "    fake_img=G(noise)\n",
        "    D_pred=D(fake_img)\n",
        "    D_fake_loss=fake_loss(D_pred)\n",
        "\n",
        "    D_pred=D(real_img)\n",
        "    D_real_loss=real_loss(D_pred)\n",
        "\n",
        "    D_loss=(D_fake_loss+D_real_loss)/2\n",
        "    total_d_loss += D_loss.item()\n",
        "\n",
        "    D_loss.backward()\n",
        "    D_opt.step()\n",
        "\n",
        "    # find the loss and update weights for Generator network\n",
        "    G_opt.zero_grad()\n",
        "    noise=torch.randn(batch_size, noise_dim, device=device)\n",
        "    fake_img=G(noise)\n",
        "    D_pred=D(fake_img)\n",
        "    G_loss=real_loss(D_pred)\n",
        "    total_g_loss += G_loss.item()\n",
        "    G_loss.backward()\n",
        "    G_opt.step()\n",
        "\n",
        "  avg_d_loss=total_d_loss/len(trainloader)\n",
        "  avg_g_loss= total_g_loss/len(trainloader)\n",
        "  print(\" Epoch:{} | D_losss: {}  | G_loss: {}\".format(i+1, avg_d_loss, avg_g_loss))\n",
        "  show_tensor_images(fake_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1IjTM2sliWa"
      },
      "source": [
        "# Run after training is completed.\n",
        "# Now you can use Generator Network to generate handwritten images\n",
        "\n",
        "noise = torch.randn(batch_size, noise_dim, device = device)\n",
        "generated_image = G(noise)\n",
        "\n",
        "show_tensor_images(generated_image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}